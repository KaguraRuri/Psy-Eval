# PsyEval: A Suite of Mental Health Related Tasks for Evaluating Large Language Models

## Overview

PsyEval is a comprehensive task suite designed to evaluate the performance of language models in the domain of mental health. This repository contains the necessary resources and documentation for understanding and replicating our experiments.


## Dataset

The dataset used in PsyEval is available in the [Datasets](datasets/). Please review the [data usage policy](processed/data-usage-policy.md) before using the dataset.

## Experiments

We conducted a series of experiments to evaluate various language models on mental health tasks. Detailed instructions for replicating these experiments can be found in the [Experiments](processed/experiments/) directory.

## Results

Our findings and results are summarized in the paper (link to the paper). For a detailed breakdown of the results, refer to the [Results](processed/results/) directory.
